{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPQY2LAR8s5z"
      },
      "source": [
        "# **Discriminante de Fisher**\n",
        "Luis Felipe Castro Corrales &ensp; 181417  \n",
        "David Emmanuel González Cázares &ensp; 198582  \n",
        "René Ochoa Sawaya &ensp; 179080  \n",
        "<hr>\n",
        "\n",
        "> Describir el modelo y la intuición. Explicar cómo se estiman los parámetros vía máxima verosimilitud. Ilustrar mediante un ejemplo.\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn74Xi3c837N"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "El discriminante de Fisher se utiliza para separar en clases una población (como especies de plantas, marcas de coches o tipos de tumores). Se le asigna una etiqueta con su clase a cada observación. \n",
        "\n",
        "Para discriminar se utilizan las observaciones etiquetadas para construir un clasificador que separe las observaciones en sus clases de la mejor manera posible.\n",
        "\n",
        "Despues se utiliza el clasificador para predecir la clase de observaciones no etiquetadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SasN3S3HG32F"
      },
      "source": [
        "# Clases y atributos\n",
        "\n",
        "La población está partida en clases sin orden. Cada elemento de la población pertenece a una y solo una clase. Todos los elementos tienen medidas variables por los cuales se le clasifica, a estas se les llaman atributos. \n",
        "\n",
        "Ejemplos de atributos pueden ser: de una persona en una población la altura, el peso, la edad; de un foco la luminosidad, su tiempo de vida, su consumo de watts por hora; de una flor su color, su consumo de agua diario su número de pétalos, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXtrlRHmHnym"
      },
      "source": [
        "# Análisis por Discriminante Lineal Gaussiano\n",
        "\n",
        "El Análisis por Discriminación Lineal tiene su origen en una publicación de R. A. Fisher en los *Anales de la Eugenesia* (Fisher,&nbsp;1936). En escencia, el discriminante propuesto por Fisher busca encontrar un vector $\\mathbf{b}$ tal que al realizar la operación $\\mathbf{b}^\\mathrm{T} \\mathbf{x}$ se maximice la separación entre clases. Actualmente, el Análisis por Discriminante Lineal toma supuestos adicionales sobre la distribución de los datos para derivar resultados sobre la probabilidad de error de clasificación y para encontrar los estimadores de máxima verosimilitud de los parámetros desconocidos.\n",
        "\n",
        "Para hacer Análisis por Discriminante Lineal Gausiano, supongamos primero que tenemos dos clases $\\Pi_1$ y $\\Pi_2$ que dan origen a un conjunto de datos. Suponemos que una observación cualquiera $\\mathbf{X}=\\mathbf{x}$ proviene de la clase $\\Pi_i$ con una *probabilidad previa* $\\pi_i$. Además supongamos que la densidad de probabilidad condicional de $\\mathbf{x}$ para la clase $i$ es \n",
        "$$\n",
        "\\mathrm{P}(\\mathbf{X}=\\mathbf{x}|\\mathbf{X}\\in\\Pi_i) = f_i(\\mathbf{x}), \\quad i =1,2.\n",
        "$$\n",
        "Recordemos que la regla de clasificación de Bayes asigna $\\mathbf{x}$ a la clase $\\Pi_i$ con la mayor *probabilidad posterior* $p(\\Pi_i|\\mathbf{x}) = \\mathrm{P}(\\mathbf{X}\\in\\Pi_i|\\mathbf{X}=\\mathbf{x})$. Así, por la Regla de Bayes, determinamos que se asigna $\\mathbf{X}$ a $\\Pi_1$ si\n",
        "\\begin{equation}\n",
        "\\tag{1} \\frac{f_1(\\mathbf{x})\\pi_1}{f_2(\\mathbf{x})\\pi_2} > 1\n",
        "\\end{equation}\n",
        "\n",
        "El Análisis por Discriminante Lineal Gausiano parte del la regla de clasificación de Bayes (1) pero añade el supuesto de que ambas densidades de probabilidad son distribuciones normales multivariadas con medias arbitrarias pero con una matriz de covarianza en común. De tal forma al sustituir las funciones $f_i(\\cdot)$ y aplicando logaritmo natural, obtenemos\n",
        "\\begin{equation}\n",
        "\\tag{2} L(\\mathbf{x}) = \\ln\\left\\{\\frac{f_1(\\mathbf{x})\\pi_1}{f_2(\\mathbf{x})\\pi_2}\\right\\} = b_0 + \\mathbf{b}^\\mathrm{T} \\mathbf{x}\n",
        "\\end{equation}\n",
        "que es una función lineal de $\\mathbf{x}$ donde\n",
        "\\begin{equation}\n",
        "\\tag{3} \\mathbf{b} = \\Sigma_\\mathbf{XX}^{-1}(\\mu_1-\\mu_2)\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\tag{4} b_0 = -\\frac{1}{2}\\left\\{\\mu_1^\\mathrm{T}\\Sigma_\\mathbf{XX}^{-1}\\mu_1 - \\mu_2^\\mathrm{T}\\Sigma_\\mathbf{XX}^{-1}\\mu_2\\right\\} + \\ln\\left\\{\\frac{\\pi_1}{\\pi_2}\\right\\}\n",
        "\\end{equation}\n",
        "\n",
        "Así, se asigna $\\mathbf{X}$ a $\\Pi_1$ si $L(\\mathbf{x})>0$, o de lo contrario, se asigna $\\mathbf{X}$ a $\\Pi_2$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heRjTgPNIcbo"
      },
      "source": [
        "## Probabilidad de error de clasificación\n",
        "\n",
        "Las observaciones se clasifican según en cual de las dos regiones de clasificación caegan. La probabilidad de clasificar erroneamente la observación es la probabilidad de que caega en la región de la clase con la que no está etiquetada. La probabilidad de error de clasificación incrementa conforme la observación se vuelve más equidistante entre las regiones de claificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BbuIvagIuWl"
      },
      "source": [
        "## Estimadores muestrales\n",
        "\n",
        "La estimación de medias de cada clase se estiman mediante las medias muestrales de los datos observados en cada clase $hat{\\boldsymbol{\\mu}}j = \\frac{1}{n_j} \\sum{i=1}^{n_j} \\mathbf{x}{ij}$. Y la estimación de la covarianza común se utiliza la matriz de covarianza muestral $\\hat{\\boldsymbol{\\Sigma}} = \\frac{1}{N - K} \\sum{j=1}^{K} \\sum_{i=1}^{n_j} (\\mathbf{x}{ij} - \\hat{\\boldsymbol{\\mu}}_j)(\\mathbf{x}{ij} - \\hat{\\boldsymbol{\\mu}}_j)^T$. Estos dos son los estimadores de máxima verosimilitud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkONsjAzI48N"
      },
      "source": [
        "# Implementación y ejemplo de clasificación\n",
        "En esta sección crearemos una función que genere un clasificador lineal y lo probaremos con la base de datos _inserte nombre de base de datos_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class LDAGaussiano:\n",
        "    def __init__(self):\n",
        "        b0 = None\n",
        "        b = None\n",
        "        clases = None\n",
        "\n",
        "\n",
        "    def entrenar(self, datos, clasific):\n",
        "        a,b = datos.shape\n",
        "        self.clases, inv, counts = np.unique(clasific, return_inverse = True, return_counts = True)\n",
        "        mu_1, mu_2 = np.zeros(b), np.zeros(b)\n",
        "        sxx_1, sxx_2 = np.zeros((b,b)), np.zeros((b,b))\n",
        "\n",
        "        for i in range(0,a):\n",
        "            if clasific[inv[i]] == self.clases[0]:\n",
        "                mu_1 += datos[i,::]\n",
        "            else:\n",
        "                mu_2 += datos[i,::]\n",
        "        mu_1 /= counts[0]\n",
        "        mu_2 /= counts[1]\n",
        "\n",
        "        for i in range(0,a):\n",
        "            if clasific[inv[i]] == self.clases[0]:\n",
        "                sxx_1 += np.outer(datos[i,::]-mu_1,datos[i,::]-mu_1)\n",
        "            else:\n",
        "                sxx_2 += np.outer(datos[i,::]-mu_2,datos[i,::]-mu_2)\n",
        "        sigma_xx = (sxx_1 + sxx_2)/a\n",
        "\n",
        "        self.b0 = -(np.inner(mu_1,np.linalg.solve(sigma_xx,mu_1)) - np.inner(mu_2,np.linalg.solve(sigma_xx,mu_2)))/2 + np.log(counts[0]/counts[1])\n",
        "        self.b = np.linalg.solve(sigma_xx,(mu_1-mu_2))\n",
        "\n",
        "        return self.b0, self.b.shape\n",
        "\n",
        "\n",
        "    def predecir(self,datos):\n",
        "        if (self.b0 is not None) and (self.b is not None):\n",
        "            sol = None\n",
        "            if datos.ndim == 1:\n",
        "                L = self.b0 + np.inner(self.b,datos)\n",
        "                if L > 0:\n",
        "                    sol = self.clases[1]\n",
        "                else:\n",
        "                    sol = self.clases[0]\n",
        "            else:\n",
        "                a,_ = datos.shape\n",
        "                sol = np.zeros(a)\n",
        "                for index, x in enumerate(datos):\n",
        "                    L = self.b0 + np.inner(self.b,x)\n",
        "                    if L > 0:\n",
        "                        sol[index] = self.clases[1]\n",
        "                    else:\n",
        "                        sol[index] = self.clases[0]\n",
        "            return sol\n",
        "        else:\n",
        "            print(\"Debes entrenar el modelo.\")\n",
        "\n",
        "    def accuracy(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 10 100\n",
            "1 11 110\n",
            "2 12 120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Felip\\AppData\\Local\\Temp\\ipykernel_24288\\3280623294.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  print(index, row[1], row[2])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1466.0602270127372, (3,))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})\n",
        "df = df.reset_index()  # make sure indexes pair with number of rows\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    print(index, row[1], row[2])\n",
        "\n",
        "datos = np.array([[2, 3, 3], [4, 5, 6],[1,9,3.5],[1,2,2],[4.5,5.5,6.6]])\n",
        "clasific = np.array([1,2,1,1,2])\n",
        "lda = LDAGaussiano()\n",
        "lda.entrenar(datos,clasific)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12163, 785) (2027, 785)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist_test = pd.read_csv('data/mnist_test_1.csv', header=None)\n",
        "mnist_train = pd.read_csv('data/mnist_train_1.csv', header=None)\n",
        "\n",
        "mnist_test = mnist_test[mnist_test[0].isin([1,5])].to_numpy()\n",
        "mnist_train = mnist_train[mnist_train[0].isin([1,5])].to_numpy()\n",
        "\n",
        "#np.savetxt(\"data/mnist_test_1.csv\", mnist_test, fmt=\"%d\", delimiter=\",\")\n",
        "#np.savetxt(\"data/mnist_train_1.csv\", mnist_train, fmt=\"%d\", delimiter=\",\")\n",
        "\n",
        "print(mnist_train.shape, mnist_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "mnist_test_y = mnist_test[::,0]\n",
        "mnist_test_x = mnist_test[::, 1:]\n",
        "mnist_train_y = mnist_train[::,0]\n",
        "mnist_train_x = mnist_train[::, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "imgplot = plt.imshow(mnist_test_x[4].reshape(28,28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(151, 1)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#np.var(array_2d, axis = 0)\n",
        "idx = np.argwhere(np.all(mnist_train_x[..., :] == 0, axis=0))\n",
        "idx.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12163, 633)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_train_x = np.delete(mnist_train_x, idx, axis=1)\n",
        "mnist_train_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2027, 633)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_test_x = np.delete(mnist_test_x, idx, axis=1)\n",
        "mnist_test_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9.758582406962178, (633,))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda = LDAGaussiano()\n",
        "lda.entrenar(mnist_train_x,mnist_train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 5., ..., 5., 1., 5.])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda_predict = lda.predecir(mnist_test_x)\n",
        "lda_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(a,b):\n",
        "    n = len(a)\n",
        "    sum = 0\n",
        "    for i in range(0,n):\n",
        "        if a[i] == b[i]:\n",
        "            sum += 1\n",
        "    return sum/n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9896398618648249"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda_accuracy = accuracy(mnist_test_y, lda_predict)\n",
        "lda_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O1Wj5wz8zcY"
      },
      "source": [
        "  # Referencias\n",
        "  \n",
        "  Izenman, A. J. (2008). *Modern multivariate statistical techniques* (Vol. 1). New York: Springer.\n",
        "\n",
        "  Fisher, R. A. (1936). *The use of multiple measurements in taxonomic problems*. Annals of eugenics, 7(2), 179-188."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
